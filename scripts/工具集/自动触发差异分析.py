#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
è‡ªåŠ¨è§¦å‘é€»è¾‘å·®å¼‚åˆ†æå·¥å…·

åŠŸèƒ½ï¼š
    å¯¹æ¯”åŸå§‹å’Œè½¬æ¢åçš„è‡ªåŠ¨è§¦å‘é€»è¾‘ï¼Œç²¾å‡†æ˜¾ç¤ºæœ€å°å·®å¼‚å•å…ƒ
    è€Œä¸æ˜¯æ˜¾ç¤ºæ•´ä¸ªè¡¨è¾¾å¼è®©ç”¨æˆ·è‡ªå·±æ‰¾å·®å¼‚

å¯¹æ¯”é€»è¾‘ï¼š
    åŸå§‹é€»è¾‘ = è‡ªåŠ¨è§¦å‘æ¡ä»¶ âˆ§ éœ€è¦æ¡ä»¶
    è½¬æ¢åé€»è¾‘ = éœ€è¦æ¡ä»¶ï¼ˆè‡ªåŠ¨è§¦å‘å›ºå®šä¸º"çœŸ"ï¼‰
"""

import os
import re
import sys
from pathlib import Path
from typing import Set, Tuple, List, Dict, Optional
from dataclasses import dataclass, field


@dataclass
class BoolExpr:
    """å¸ƒå°”è¡¨è¾¾å¼èŠ‚ç‚¹"""
    raw: str  # åŸå§‹æ–‡æœ¬
    op: Optional[str] = None  # æ“ä½œç¬¦: 'and', 'or', 'not', 'atom'
    children: List['BoolExpr'] = field(default_factory=list)
    
    def __hash__(self):
        return hash(self.raw)
    
    def __eq__(self, other):
        if isinstance(other, BoolExpr):
            return self.raw.strip() == other.raw.strip()
        return False
    
    def __repr__(self):
        return f"BoolExpr({self.op}: {self.raw[:50]}...)"


def tokenize_logic(text: str) -> List[str]:
    """åˆ†è¯é€»è¾‘è¡¨è¾¾å¼"""
    text = text.strip()
    tokens = []
    i = 0
    
    # å®šä¹‰æ“ä½œç¬¦ï¼ˆæŒ‰é•¿åº¦é™åºï¼Œé¿å…éƒ¨åˆ†åŒ¹é…ï¼‰
    operators = ['âˆ§', 'âˆ¨', 'âˆ§ not', 'âˆ¨ not', 'not ', '(', ')', '<=', '>=', '<', '>', '==', '!=', '=']
    
    while i < len(text):
        # è·³è¿‡ç©ºç™½
        if text[i].isspace():
            i += 1
            continue
        
        # æ£€æŸ¥æ“ä½œç¬¦
        matched = False
        for op in operators:
            if text[i:].startswith(op):
                tokens.append(op.strip())
                i += len(op)
                matched = True
                break
        
        if matched:
            continue
        
        # è¯»å–åŸå­è¡¨è¾¾å¼ï¼ˆæ‹¬å·å†…çš„å†…å®¹æˆ–æ™®é€šæ–‡æœ¬ï¼‰
        if text[i] == '(':
            # åŒ¹é…æ‹¬å·
            depth = 1
            j = i + 1
            while j < len(text) and depth > 0:
                if text[j] == '(':
                    depth += 1
                elif text[j] == ')':
                    depth -= 1
                j += 1
            tokens.append(text[i:j])
            i = j
        else:
            # è¯»å–åˆ°ä¸‹ä¸€ä¸ªæ“ä½œç¬¦æˆ–æ‹¬å·
            j = i
            while j < len(text):
                if text[j] in '()âˆ§âˆ¨' or text[j:].startswith('not '):
                    break
                j += 1
            if j > i:
                tokens.append(text[i:j].strip())
            i = j
    
    return [t for t in tokens if t]


def parse_logic(text: str) -> BoolExpr:
    """è§£æå¸ƒå°”è¡¨è¾¾å¼ä¸ºæ ‘ç»“æ„"""
    text = text.strip()
    
    # å»é™¤å¤–å±‚æ‹¬å·
    while text.startswith('(') and text.endswith(')'):
        inner = text[1:-1].strip()
        # æ£€æŸ¥æ‹¬å·æ˜¯å¦åŒ¹é…
        depth = 0
        valid = True
        for c in inner:
            if c == '(':
                depth += 1
            elif c == ')':
                depth -= 1
            if depth < 0:
                valid = False
                break
        if valid and depth == 0:
            text = inner
        else:
            break
    
    # æ£€æŸ¥æ˜¯å¦æ˜¯ not è¡¨è¾¾å¼
    if text.startswith('not '):
        inner = text[4:].strip()
        child = parse_logic(inner)
        return BoolExpr(raw=text, op='not', children=[child])
    
    # åˆ†è¯
    tokens = tokenize_logic(text)
    if not tokens:
        return BoolExpr(raw=text, op='atom')
    
    # æŸ¥æ‰¾é¡¶å±‚çš„ âˆ¨ (or)
    depth = 0
    for i, token in enumerate(tokens):
        if token == '(':
            depth += 1
        elif token == ')':
            depth -= 1
        elif token == 'âˆ¨' and depth == 0:
            left = ''.join(tokens[:i]).strip()
            right = ''.join(tokens[i+1:]).strip()
            left_expr = parse_logic(left)
            right_expr = parse_logic(right)
            return BoolExpr(raw=text, op='or', children=[left_expr, right_expr])
    
    # æŸ¥æ‰¾é¡¶å±‚çš„ âˆ§ (and)
    depth = 0
    for i, token in enumerate(tokens):
        if token == '(':
            depth += 1
        elif token == ')':
            depth -= 1
        elif token == 'âˆ§' and depth == 0:
            left = ''.join(tokens[:i]).strip()
            right = ''.join(tokens[i+1:]).strip()
            left_expr = parse_logic(left)
            right_expr = parse_logic(right)
            return BoolExpr(raw=text, op='and', children=[left_expr, right_expr])
    
    # åŸå­è¡¨è¾¾å¼
    return BoolExpr(raw=text, op='atom')


def get_all_atoms(expr: BoolExpr) -> Set[str]:
    """è·å–è¡¨è¾¾å¼ä¸­æ‰€æœ‰åŸå­æ¡ä»¶"""
    atoms = set()
    
    def traverse(e: BoolExpr):
        if e.op == 'atom':
            atoms.add(e.raw.strip())
        else:
            for child in e.children:
                traverse(child)
    
    traverse(expr)
    return atoms


def find_differences(original: BoolExpr, converted: BoolExpr) -> Tuple[Set[str], Set[str]]:
    """
    æ‰¾å‡ºä¸¤ä¸ªè¡¨è¾¾å¼ä¹‹é—´çš„æœ€å°å·®å¼‚
    
    è¿”å›: (åªåœ¨åŸå§‹ä¸­å­˜åœ¨çš„åŸå­æ¡ä»¶, åªåœ¨è½¬æ¢åä¸­å­˜åœ¨çš„åŸå­æ¡ä»¶)
    """
    original_atoms = get_all_atoms(original)
    converted_atoms = get_all_atoms(converted)
    
    only_in_original = original_atoms - converted_atoms
    only_in_converted = converted_atoms - original_atoms
    
    return only_in_original, only_in_converted


def normalize_condition(text: str) -> str:
    """è§„èŒƒåŒ–æ¡ä»¶æ–‡æœ¬ï¼Œç”¨äºæ¯”è¾ƒ"""
    # å»é™¤å¤šä½™ç©ºç™½
    text = ' '.join(text.split())
    # ç»Ÿä¸€å¼•å·
    text = text.replace('"', '').replace("'", '')
    # å»é™¤æ‹¬å·å·®å¼‚
    text = text.strip('()')
    return text.strip()


def smart_diff(original_text: str, converted_text: str) -> Tuple[List[str], List[str]]:
    """
    æ™ºèƒ½å·®å¼‚åˆ†æ
    
    è¿”å›: (ç§»é™¤çš„æ¡ä»¶åˆ—è¡¨, æ–°å¢çš„æ¡ä»¶åˆ—è¡¨)
    """
    # è§£æè¡¨è¾¾å¼
    original_expr = parse_logic(original_text)
    converted_expr = parse_logic(converted_text)
    
    # è·å–åŸå­æ¡ä»¶
    only_in_original, only_in_converted = find_differences(original_expr, converted_expr)
    
    # è¿›ä¸€æ­¥å¤„ç†ï¼Œè¯†åˆ«ç»“æ„æ€§å˜åŒ–
    # ä¾‹å¦‚ï¼šåŸå§‹æ˜¯ (A âˆ§ B) âˆ¨ (A âˆ§ C) è½¬æ¢åæ˜¯ A âˆ§ (B âˆ¨ C)
    
    removed = sorted(only_in_original)
    added = sorted(only_in_converted)
    
    return removed, added


def extract_logic_from_report(report_path: str) -> List[Dict]:
    """ä»ç°æœ‰æŠ¥å‘Šä¸­æå–é€»è¾‘å¯¹æ¯”æ•°æ®"""
    if not os.path.exists(report_path):
        return []
    
    with open(report_path, 'r', encoding='utf-8') as f:
        content = f.read()
    
    results = []
    
    # åŒ¹é…æ¯ä¸ªèŠ‚çš„å·®å¼‚
    # æ ¼å¼ï¼šã€æ•°å­—ã€‘æ–‡ä»¶è·¯å¾„ [èŠ‚å]
    section_pattern = r'ã€\d+ã€‘([^\[]+)\[([^\]]+)\]'
    
    # åŒ¹é…å·®å¼‚å†…å®¹
    diff_pattern = r'åŸå§‹æœ‰è€Œè½¬æ¢åç¼ºå°‘:\s*(.+?)(?=\s*è½¬æ¢åæ–°å¢:|$)'
    add_pattern = r'è½¬æ¢åæ–°å¢:\s*(.+?)(?=\s*ã€|\Z)'
    
    # æŒ‰èŠ‚åˆ†å‰²
    parts = re.split(r'(?=ã€\d+ã€‘)', content)
    
    for part in parts:
        section_match = re.search(section_pattern, part)
        if not section_match:
            continue
        
        file_path = section_match.group(1).strip()
        section_name = section_match.group(2).strip()
        
        # æå–åŸå§‹å’Œè½¬æ¢åçš„é€»è¾‘
        original_match = re.search(r'åŸå§‹æœ‰è€Œè½¬æ¢åç¼ºå°‘:\s*(.+?)(?=\s*è½¬æ¢åæ–°å¢:|$)', part, re.DOTALL)
        converted_match = re.search(r'è½¬æ¢åæ–°å¢:\s*(.+?)(?=\s*ã€|\Z)', part, re.DOTALL)
        
        if original_match and converted_match:
            original_logic = original_match.group(1).strip().replace('\n', ' ')
            converted_logic = converted_match.group(1).strip().replace('\n', ' ')
            
            results.append({
                'file': file_path,
                'section': section_name,
                'original': original_logic,
                'converted': converted_logic
            })
    
    return results


def generate_precise_diff_report(logic_data: List[Dict], output_path: str):
    """ç”Ÿæˆç²¾å‡†çš„å·®å¼‚æŠ¥å‘Š"""
    lines = []
    lines.append("=" * 80)
    lines.append("è‡ªåŠ¨è§¦å‘é€»è¾‘å·®å¼‚ç²¾å‡†åˆ†ææŠ¥å‘Š")
    lines.append("=" * 80)
    lines.append("")
    lines.append("æ£€æŸ¥é€»è¾‘:")
    lines.append("  åŸå§‹é€»è¾‘ = è‡ªåŠ¨è§¦å‘æ¡ä»¶ âˆ§ éœ€è¦æ¡ä»¶")
    lines.append("  è½¬æ¢åé€»è¾‘ = éœ€è¦æ¡ä»¶ï¼ˆè‡ªåŠ¨è§¦å‘å›ºå®šä¸º'çœŸ'ï¼‰")
    lines.append("")
    lines.append("=" * 80)
    lines.append("")
    
    for i, item in enumerate(logic_data, 1):
        file_path = item['file']
        section_name = item['section']
        original = item['original']
        converted = item['converted']
        
        # è®¡ç®—å·®å¼‚
        removed, added = smart_diff(original, converted)
        
        # å¦‚æœæ²¡æœ‰å®è´¨å·®å¼‚ï¼Œè·³è¿‡
        if not removed and not added:
            continue
        
        lines.append(f"ã€{i}ã€‘{file_path} [{section_name}]")
        lines.append("")
        
        if removed:
            lines.append("  âŒ ç§»é™¤çš„æ¡ä»¶:")
            for cond in removed:
                lines.append(f"     - {cond}")
            lines.append("")
        
        if added:
            lines.append("  âœ… æ–°å¢çš„æ¡ä»¶:")
            for cond in added:
                lines.append(f"     + {cond}")
            lines.append("")
        
        # æ˜¾ç¤ºåŸå§‹å®Œæ•´é€»è¾‘ï¼ˆå¯é€‰ï¼Œç”¨äºå‚è€ƒï¼‰
        lines.append("  ğŸ“‹ åŸå§‹å®Œæ•´é€»è¾‘:")
        lines.append(f"     {original[:200]}{'...' if len(original) > 200 else ''}")
        lines.append("")
        lines.append("  ğŸ“‹ è½¬æ¢åå®Œæ•´é€»è¾‘:")
        lines.append(f"     {converted[:200]}{'...' if len(converted) > 200 else ''}")
        lines.append("")
        lines.append("-" * 80)
        lines.append("")
    
    # å†™å…¥æ–‡ä»¶
    with open(output_path, 'w', encoding='utf-8') as f:
        f.write('\n'.join(lines))
    
    return '\n'.join(lines)


def main():
    """ä¸»å‡½æ•°"""
    # è¾“å…¥è¾“å‡ºè·¯å¾„
    input_report = 'scripts/æ•°æ®é›†/è‡ªåŠ¨è§¦å‘å·®å¼‚æŠ¥å‘Š.txt'
    output_report = 'scripts/æ•°æ®é›†/è‡ªåŠ¨è§¦å‘å·®å¼‚ç²¾å‡†æŠ¥å‘Š.txt'
    
    print("=" * 60)
    print("è‡ªåŠ¨è§¦å‘é€»è¾‘å·®å¼‚ç²¾å‡†åˆ†æ")
    print("=" * 60)
    
    # æ£€æŸ¥è¾“å…¥æ–‡ä»¶
    if not os.path.exists(input_report):
        print(f"é”™è¯¯: æ‰¾ä¸åˆ°è¾“å…¥æŠ¥å‘Š: {input_report}")
        sys.exit(1)
    
    print(f"\nè¯»å–åŸå§‹æŠ¥å‘Š: {input_report}")
    
    # æå–é€»è¾‘æ•°æ®
    logic_data = extract_logic_from_report(input_report)
    print(f"æå–äº† {len(logic_data)} ä¸ªèŠ‚çš„é€»è¾‘æ•°æ®")
    
    # ç”Ÿæˆç²¾å‡†æŠ¥å‘Š
    print("\næ­£åœ¨åˆ†æå·®å¼‚...")
    report_content = generate_precise_diff_report(logic_data, output_report)
    
    # è¾“å‡ºæ‘˜è¦
    print("\n" + "=" * 60)
    print("åˆ†æå®Œæˆ!")
    print(f"æŠ¥å‘Šå·²ä¿å­˜: {output_report}")
    
    # æ˜¾ç¤ºå‰3ä¸ªç¤ºä¾‹
    print("\n" + "=" * 60)
    print("å·®å¼‚ç¤ºä¾‹ (å‰3ä¸ª):")
    print("=" * 60)
    
    count = 0
    for item in logic_data[:3]:
        removed, added = smart_diff(item['original'], item['converted'])
        if removed or added:
            count += 1
            print(f"\nã€{count}ã€‘{item['file']} [{item['section']}]")
            
            if removed:
                print("  âŒ ç§»é™¤:")
                for cond in list(removed)[:2]:  # æœ€å¤šæ˜¾ç¤º2ä¸ª
                    print(f"     - {cond[:80]}{'...' if len(cond) > 80 else ''}")
            
            if added:
                print("  âœ… æ–°å¢:")
                for cond in list(added)[:2]:  # æœ€å¤šæ˜¾ç¤º2ä¸ª
                    print(f"     + {cond[:80]}{'...' if len(cond) > 80 else ''}")
    
    if count == 0:
        print("\næ²¡æœ‰å‘ç°å®è´¨æ€§å·®å¼‚")


if __name__ == "__main__":
    main()
